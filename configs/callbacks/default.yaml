model_checkpoint:
  _target_: lightning.pytorch.callbacks.ModelCheckpoint
  dirpath: ${paths.checkpoints}
  monitor: valid/scaled_loss
  mode: min
  save_last: True
  save_top_k: -1

early_stopping:
  _target_: lightning.pytorch.callbacks.EarlyStopping
  monitor: valid/scaled_loss
  mode: min
  patience: 9999

# lr_monitor:
#   _target_: lightning.pytorch.callbacks.LearningRateMonitor
#   logging_interval: step

timer:
  _target_: lightning.pytorch.callbacks.Timer
  duration: "14:00:00:00"
